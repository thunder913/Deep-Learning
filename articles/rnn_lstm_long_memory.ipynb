{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do RNN and LSTM have Long Memory?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Jingyu Zhao, Feiqing Huang, Jia Lv, Yanjie Duan, Zhen Qin, Guodong Li, Guangjian Tian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Published in: 37th International Conference on Machine Learning, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper investigates whether Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks truly have long memoryâ€”the ability to retain information for a long time. Even though LSTMs were designed to overcome the short memory issue in RNNs, the authors show that both RNNs and LSTMs do not have long memory from a statistical perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Problem\n",
    "\n",
    "In machine learning we usually work with sequential data and the models like RNNs struggle with remembering long-term patterns, due to the vanishing gradient problem - old information fades away as the sequence gets longer and longer. Working with deep learning algorithms usually means working with very big datasets and for the model to forget the first passed data is a big issue. LSTMs are designed to fix this problem, but the researchers in the article are going to question, how truly long term memory does it have.\n",
    " \n",
    " The article mentions some related past research, that has been conducted on this topic. First it mentions that traditional statistical models can handle long memory well, but are not flexible like neural networks. There are also some researches on LSTM's long term memory, but they are very little count. There have been some alternatives to RNN, that try to keep long term memory. The model from this article will be compared with them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Memory property of recurrent networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is long term memory from statistical perspective?\n",
    "Explain some formulas\n",
    "\n",
    "\n",
    "RN process\n",
    "RNN cannot maintain long meemory, while LSTM can\\\n",
    "\n",
    "Proving RNN and lSTM have no logn term memory - RNN has no and LSTM fades aggressively\n",
    "\n",
    "The new long memory definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Long Memory Recurrent Networks\n",
    "\n",
    "Explain how it works and what it is\n",
    "and then the experiments and if it truly works"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
