{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on Production of Oil Well with AttentionCNN-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: S Pan, J Wang, W Zhou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Published in: Journal of Physics: Conference Series (Volume 2030, Paper 012038), 2021. Presented at ICEECT 2021 conference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper investigates whether Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks truly have long memoryâ€”the ability to retain information for a long time. Even though LSTMs were designed to overcome the short memory issue in RNNs, the authors show that both RNNs and LSTMs do not have long memory from a statistical perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oil well production prediction is crucial for efficient resource management in the petroleum industry. Traditional methods like curve analysis and mathematical modeling are limited in accuracy due to the complexity of external factors affecting production. Machine learning techniques, such as ARIMA, BP neural networks, and SVR, have been used but suffer from limitations like data stability requirements, poor scalability, and susceptibility to local minima. Deep learning approaches, including CNNs and LSTMs, offer better predictive power, but individual models struggle with stability in long-term sequence forecasting. The Attention-CNN-LSTM model is proposed to address these challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Related work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the early stage of oilfield development, the curve analysis method and mathematical modeling methods are widely used. \n",
    "\n",
    "The authors mention, that \"The traditional machine learning methods generally require, that all data should be put into the memory during training\". I disagree with them on this topic. In some models - yes we require a lot of the data initially in memory to have correct weights, but still we can expertiment and do fine with partial fitting the data. \n",
    "\n",
    "Currently LSTM's are used in production predictions of an oil well and have achieved good results. However, due to the harsh udnerground production envrionment, the oil production data usually contains multiple noise components, which are non linear and non stationary time series. That is the reason, why the paper combines CNN, LSTM and Attention mechanism to construct a production prediction model. I also disagree partially with that, since LSTM alone is enough to handle nonlinear data, due to the gated mechanism, that allow it to capture complex dependendencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\{\\hat{y}_t\\}_{t=T+1}^{T+\\Delta} = F\\left(\\{x_t\\}_{t=1}^{T}, \\{y_t\\}_{t=1}^{T} \\right)$$\n",
    "\n",
    "The production prediction of an oil well uses the timeseries of X and the actual oil well production y as inputs to construct a model to predict y in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model, that will be constructed is constisting of:\n",
    "\n",
    "- CNN\n",
    "\n",
    "The input data will be passed to the CNN layer. It can babstract and express the original oil production data at a higher level. The features of the original oil production data are processed by CNN, the correlation between the multi-dimensional data is mined and noises are removed.\n",
    "\n",
    "- LSTM\n",
    "\n",
    "The data is passed on to LSTM layers.\n",
    "\n",
    "- Attention\n",
    "\n",
    "The attention can be used to extract the salient features in the sub-sequences of long-time sequence and applied to calculate the weighted sumation for the vector expression of the hidden layer of the LSTM output.\n",
    "\n",
    "Finally we end up with the following structuri - Attention-CNN-LSTM\n",
    "\n",
    "<img src=\"./attention_cnn_lstm.png\" alt=\"drawing\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training\n",
    "\n",
    "The model is trained on data from an oilfield in souther China and includes the T1 and T2 wells. \n",
    "\n",
    "The metrics, that will determine, how good the model is will be RMSE, MAE and MAPE.\n",
    "\n",
    "Those are the results the authors have provided us:\n",
    "\n",
    "<img src=\"./results_comparison.png\" alt=\"drawing\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the proposed model is performing much better than all the other models on the T1 and T2 datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention-CNN-LSTM is more suitable for predicting the time series data such as oil well production than the compared models.\n",
    "\n",
    "The models seems to correctly extract high-dimensional features using the CNN and with attention and LSTM manages to avoid the gradiend explosion and get the important features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors have provided the actual code for free from their github page. I have put it in the folder mrnn_mlstm_experiment. To run it we just follow the instructions in the readme file. Basically we run the following command:\n",
    "\n",
    "python .\\train.py --dataset '{dataset}' --algorithm '{the algorithm}' --epochs 50\n",
    "\n",
    "I have chosen to run it on 'tree7' as dataset and on DJI (Dow Jones Index) and those are the results for MLSTM:\n",
    "\n",
    "tree7:\n",
    "RMSE:[0.2990356773379933]\n",
    "MAE:[0.23424398632834936]\n",
    "\n",
    "DJI:\n",
    "\n",
    "\n",
    "\n",
    "LSTM results for comparison:\n",
    "tree7\n",
    "\n",
    "\n",
    "DJI:\n",
    "\n",
    "\n",
    "\n",
    "TODO show some chart and validate with the provided stuff in the article\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
